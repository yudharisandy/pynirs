{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aq5dbT2kZq0L"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "This code was created for thesis,\n",
        "by Yudha Putra Arisandy\n",
        "Departement of Computer Science\n",
        "IPB University\n",
        "\"\"\"\n",
        "\n",
        "#1. Import library\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "df = pd.read_excel('Data Pre-Riset.xlsx', sheet_name='main')\n",
        "#print(df.head(5))\n",
        "#print(df.isnull().sum())\n",
        "df.describe().transpose()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8NJ79vrvtLO"
      },
      "outputs": [],
      "source": [
        "df = df.drop('Panjang Gelombang (nm)',axis=1)\n",
        "df = df.drop('N',axis=1)\n",
        "df = df.drop('P',axis=1)\n",
        "\n",
        "X = df.drop('N',axis=1)\n",
        "y = df['N']\n",
        "\n",
        "#split into 70:30 ration\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAa0ow-6BcJ6"
      },
      "outputs": [],
      "source": [
        "# Preprocessing Random Oversampling\n",
        "# SMOGN\n",
        "!pip install smogn\n",
        "\n",
        "# load libraries\n",
        "import smogn\n",
        "import pandas\n",
        "## conduct smogn\n",
        "df_smogn = smogn.smoter(\n",
        "    \n",
        "    ## main arguments\n",
        "    data = df,           ## pandas dataframe\n",
        "    y = 'K',          ## string ('header name')\n",
        "    k = 9,                    ## positive integer (k < n) , 9, 12\n",
        "    samp_method = 'extreme',  ## string ('balance' or 'extreme')\n",
        "\n",
        "    ## phi relevance arguments\n",
        "    rel_thres = 0.99,         ## positive real number (0 < R < 1), 0.99\n",
        "    rel_method = 'auto',      ## string ('auto' or 'manual')\n",
        "    rel_xtrm_type = 'high',   ## string ('low' or 'both' or 'high')\n",
        "    rel_coef = 0.9           ## positive real number (0 < R), 0.9, 3.6\n",
        ")\n",
        "df_smogn.to_csv('df_smogn_k.csv')\n",
        "df_smogn.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-pDxLmbHtrq"
      },
      "outputs": [],
      "source": [
        "X = df_smogn.drop('N',axis=1)\n",
        "y = df_smogn['N']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0XoDGvy_BEE"
      },
      "outputs": [],
      "source": [
        "#read df_smogn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "df = pd.read_csv('df_smogn_n.csv')\n",
        "#print(df.head(5))\n",
        "#print(df.isnull().sum())\n",
        "df = df.drop('Unnamed: 0',axis=1)\n",
        "df.describe().transpose()\n",
        "X = df.drop('N',axis=1)\n",
        "y = df['N']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwQp7ViySgOR"
      },
      "outputs": [],
      "source": [
        "#Preprocessing: Principal Component Analysis (PCA)\n",
        "# calculate matriks covariance\n",
        "features = X.T\n",
        "cov_matrix = np.cov(features)\n",
        "cov_matrix[:5]\n",
        "\n",
        "#Eigen Decomposition\n",
        "values, vectors = np.linalg.eig(cov_matrix)\n",
        "values=values.real\n",
        "vectors=vectors.real\n",
        "values[:5]\n",
        "\n",
        "explained_variances = []\n",
        "for i in range(len(values)):\n",
        " explained_variances.append(values[i] / np.sum(values))\n",
        "print(np.sum(explained_variances), '\\n', explained_variances)\n",
        "\n",
        "projected_1 = X.dot(vectors.T[0])\n",
        "projected_2 = X.dot(vectors.T[1])\n",
        "projected_3 = X.dot(vectors.T[2])\n",
        "projected_4 = X.dot(vectors.T[3])\n",
        "projected_5 = X.dot(vectors.T[4])\n",
        "projected_6 = X.dot(vectors.T[5])\n",
        "projected_7 = X.dot(vectors.T[6])\n",
        "projected_8 = X.dot(vectors.T[7])\n",
        "projected_9 = X.dot(vectors.T[8])\n",
        "projected_10 = X.dot(vectors.T[9])\n",
        "df_pca = pd.DataFrame(projected_1, columns=['PC1'])\n",
        "df_pca['PC2'] = projected_2\n",
        "df_pca['PC3'] = projected_3\n",
        "df_pca['PC4'] = projected_4\n",
        "df_pca['PC5'] = projected_5\n",
        "df_pca['PC6'] = projected_6\n",
        "df_pca['PC7'] = projected_7\n",
        "df_pca['PC8'] = projected_8\n",
        "df_pca['PC9'] = projected_9\n",
        "df_pca['PC10'] = projected_10\n",
        "df_pca['N'] = y\n",
        "df_pca.to_csv('df_pca10_n.csv')\n",
        "df_pca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htJiMALeXinN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(20, 10))\n",
        "sns.scatterplot(df_pca['PC1'], [0] * len(df_pca), hue=df_pca['K'], s=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "uPL38rKW7UFd",
        "outputId": "efedbda2-9c1e-4c0b-cd58-832a41d5f0ca"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3cd2c128-af68-4827-9a38-5bb4c007ece3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A1</th>\n",
              "      <th>A2</th>\n",
              "      <th>A3</th>\n",
              "      <th>A4</th>\n",
              "      <th>A5</th>\n",
              "      <th>A6</th>\n",
              "      <th>A7</th>\n",
              "      <th>A8</th>\n",
              "      <th>A9</th>\n",
              "      <th>A10</th>\n",
              "      <th>...</th>\n",
              "      <th>A127</th>\n",
              "      <th>A128</th>\n",
              "      <th>A129</th>\n",
              "      <th>A130</th>\n",
              "      <th>A131</th>\n",
              "      <th>A132</th>\n",
              "      <th>A133</th>\n",
              "      <th>A134</th>\n",
              "      <th>A135</th>\n",
              "      <th>A136</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>28.114081</td>\n",
              "      <td>29.361163</td>\n",
              "      <td>30.884066</td>\n",
              "      <td>32.699464</td>\n",
              "      <td>33.876546</td>\n",
              "      <td>33.356672</td>\n",
              "      <td>31.483338</td>\n",
              "      <td>29.696028</td>\n",
              "      <td>28.869327</td>\n",
              "      <td>28.822636</td>\n",
              "      <td>...</td>\n",
              "      <td>20.342996</td>\n",
              "      <td>20.793190</td>\n",
              "      <td>21.211703</td>\n",
              "      <td>21.415654</td>\n",
              "      <td>21.433938</td>\n",
              "      <td>21.368281</td>\n",
              "      <td>21.283481</td>\n",
              "      <td>21.207955</td>\n",
              "      <td>21.129872</td>\n",
              "      <td>21.024427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>42.394687</td>\n",
              "      <td>44.031993</td>\n",
              "      <td>45.947607</td>\n",
              "      <td>48.618066</td>\n",
              "      <td>50.523599</td>\n",
              "      <td>49.695784</td>\n",
              "      <td>46.729314</td>\n",
              "      <td>43.990654</td>\n",
              "      <td>42.744388</td>\n",
              "      <td>42.634062</td>\n",
              "      <td>...</td>\n",
              "      <td>29.483534</td>\n",
              "      <td>30.000390</td>\n",
              "      <td>30.457047</td>\n",
              "      <td>30.626230</td>\n",
              "      <td>30.540834</td>\n",
              "      <td>30.340359</td>\n",
              "      <td>30.145099</td>\n",
              "      <td>29.999475</td>\n",
              "      <td>29.852202</td>\n",
              "      <td>29.673577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>34.772402</td>\n",
              "      <td>36.488100</td>\n",
              "      <td>38.457888</td>\n",
              "      <td>41.044776</td>\n",
              "      <td>42.946839</td>\n",
              "      <td>42.449510</td>\n",
              "      <td>40.187155</td>\n",
              "      <td>38.320790</td>\n",
              "      <td>37.730555</td>\n",
              "      <td>37.736337</td>\n",
              "      <td>...</td>\n",
              "      <td>27.690870</td>\n",
              "      <td>28.026678</td>\n",
              "      <td>28.459668</td>\n",
              "      <td>28.664403</td>\n",
              "      <td>28.629969</td>\n",
              "      <td>28.478459</td>\n",
              "      <td>28.313935</td>\n",
              "      <td>28.186879</td>\n",
              "      <td>28.052436</td>\n",
              "      <td>27.858059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>69.287004</td>\n",
              "      <td>71.848785</td>\n",
              "      <td>74.971332</td>\n",
              "      <td>79.392804</td>\n",
              "      <td>82.630211</td>\n",
              "      <td>81.463206</td>\n",
              "      <td>76.750560</td>\n",
              "      <td>72.265357</td>\n",
              "      <td>70.133068</td>\n",
              "      <td>69.897027</td>\n",
              "      <td>...</td>\n",
              "      <td>51.382490</td>\n",
              "      <td>52.186440</td>\n",
              "      <td>52.902367</td>\n",
              "      <td>53.257659</td>\n",
              "      <td>53.341490</td>\n",
              "      <td>53.245672</td>\n",
              "      <td>53.001058</td>\n",
              "      <td>52.718671</td>\n",
              "      <td>52.490217</td>\n",
              "      <td>52.295635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>49.234061</td>\n",
              "      <td>51.627546</td>\n",
              "      <td>54.345052</td>\n",
              "      <td>57.848022</td>\n",
              "      <td>60.354528</td>\n",
              "      <td>59.520826</td>\n",
              "      <td>56.150883</td>\n",
              "      <td>53.237958</td>\n",
              "      <td>52.190925</td>\n",
              "      <td>52.213019</td>\n",
              "      <td>...</td>\n",
              "      <td>40.786171</td>\n",
              "      <td>41.557619</td>\n",
              "      <td>42.405378</td>\n",
              "      <td>42.885599</td>\n",
              "      <td>43.005343</td>\n",
              "      <td>42.906346</td>\n",
              "      <td>42.700386</td>\n",
              "      <td>42.503897</td>\n",
              "      <td>42.346906</td>\n",
              "      <td>42.173458</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 136 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cd2c128-af68-4827-9a38-5bb4c007ece3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3cd2c128-af68-4827-9a38-5bb4c007ece3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3cd2c128-af68-4827-9a38-5bb4c007ece3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           A1         A2         A3         A4         A5         A6  \\\n",
              "10  28.114081  29.361163  30.884066  32.699464  33.876546  33.356672   \n",
              "28  42.394687  44.031993  45.947607  48.618066  50.523599  49.695784   \n",
              "22  34.772402  36.488100  38.457888  41.044776  42.946839  42.449510   \n",
              "31  69.287004  71.848785  74.971332  79.392804  82.630211  81.463206   \n",
              "38  49.234061  51.627546  54.345052  57.848022  60.354528  59.520826   \n",
              "\n",
              "           A7         A8         A9        A10  ...       A127       A128  \\\n",
              "10  31.483338  29.696028  28.869327  28.822636  ...  20.342996  20.793190   \n",
              "28  46.729314  43.990654  42.744388  42.634062  ...  29.483534  30.000390   \n",
              "22  40.187155  38.320790  37.730555  37.736337  ...  27.690870  28.026678   \n",
              "31  76.750560  72.265357  70.133068  69.897027  ...  51.382490  52.186440   \n",
              "38  56.150883  53.237958  52.190925  52.213019  ...  40.786171  41.557619   \n",
              "\n",
              "         A129       A130       A131       A132       A133       A134  \\\n",
              "10  21.211703  21.415654  21.433938  21.368281  21.283481  21.207955   \n",
              "28  30.457047  30.626230  30.540834  30.340359  30.145099  29.999475   \n",
              "22  28.459668  28.664403  28.629969  28.478459  28.313935  28.186879   \n",
              "31  52.902367  53.257659  53.341490  53.245672  53.001058  52.718671   \n",
              "38  42.405378  42.885599  43.005343  42.906346  42.700386  42.503897   \n",
              "\n",
              "         A135       A136  \n",
              "10  21.129872  21.024427  \n",
              "28  29.852202  29.673577  \n",
              "22  28.052436  27.858059  \n",
              "31  52.490217  52.295635  \n",
              "38  42.346906  42.173458  \n",
              "\n",
              "[5 rows x 136 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#Variable to save the result in .csv\n",
        "pc='raw'\n",
        "unsur='k'\n",
        "\n",
        "#df_pca = pd.read_csv('df_pca10_k.csv')\n",
        "#df_pca = pd.read_excel('df_smogn_p.xlsx')\n",
        "#df_pca = pd.read_csv('df_smogn_k.csv')\n",
        "df_pca = pd.read_excel('df_raw_k.xlsx')\n",
        "#df_pca.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "df_pca.head(5)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = df_pca.drop('K',axis=1)\n",
        "y = df_pca['K']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "X_train.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROdgF1vDPEGd"
      },
      "outputs": [],
      "source": [
        "#1. Random Forest\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn import metrics\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters={\n",
        "    'n_estimators': [100, 200, 400, 600, 800, 1000], #200, 400, 600, 800, 1000\n",
        "    'max_depth': [None, 10, 30, 50], #10, 30, 50\n",
        "    'min_samples_split':[2, 5], #2, 5\n",
        "    'min_samples_leaf': [1, 3], #1, 3\n",
        "    'bootstrap': [False, True]\n",
        "    }\n",
        "\n",
        "rf = RandomForestRegressor()\n",
        "regr_rf = GridSearchCV(rf, parameters)\n",
        "regr_rf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = regr_rf.predict(X_test)\n",
        "\n",
        "r2=regr_rf.best_score_\n",
        "rmse=np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
        "mape=np.mean(np.abs((y_test - y_pred)/y_test))*100\n",
        "nse=1-(np.sum((y_test-y_pred)**2)/np.sum((y_test-np.mean(y_pred))**2))\n",
        "akurasi=100-np.mean(np.abs((y_test - y_pred)/y_test))*100\n",
        "best_estimator=regr_rf.best_estimator_\n",
        "best_param= regr_rf.best_params_\n",
        "\n",
        "print(\"Random Forest\")\n",
        "print('R2     :', r2)\n",
        "print('RMSE   :', rmse)\n",
        "print('MAPE   :', mape)\n",
        "print('NSE    :', nse)\n",
        "print('AKURASI:', akurasi)\n",
        "print(\"\\n Results from Grid Search \" )\n",
        "print(\"\\n The best estimator across ALL searched params:\\n\", best_estimator)\n",
        "print(\"\\n The best parameters across ALL searched params:\\n\", best_param)\n",
        "\n",
        "#Simpan semua hasil statistik dalam file csv\n",
        "import csv  \n",
        "header1 = ['R2', 'RMSE', 'MAPE', 'NSE', 'AKURASI', 'Best Estimator', 'Best Parameter']\n",
        "data1 = [r2, rmse, mape, nse, akurasi, best_estimator, best_param]\n",
        "header2 = ['y_test']\n",
        "data2 = [y_test]\n",
        "header3 = ['y_pred']\n",
        "data3 = [y_pred]\n",
        "\n",
        "model='rf'\n",
        "nama_file='data_statistik' + '_' + model + '_' + pc + '_' + unsur + '.csv'\n",
        "\n",
        "with open(nama_file, 'w', encoding='UTF8') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(header1)\n",
        "    writer.writerow(data1)\n",
        "    writer.writerow(\"\\n\")\n",
        "    writer.writerow(header2)\n",
        "    writer.writerow(data2)\n",
        "    writer.writerow(\"\\n\")\n",
        "    writer.writerow(header3)\n",
        "    writer.writerow(data3)\n",
        "\n",
        "# Plot grafik regresi\n",
        "plt.scatter(y_test,y_pred)\n",
        "plt.plot(y_test,y_test,'r')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "id": "4lfTanXe-Gun",
        "outputId": "044f3b34-e685-4ef7-c066-267830c5bb9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient Boosting\n",
            "R2     : 0.23669635600618633\n",
            "RMSE   : 6.149393221801956\n",
            "MAPE   : 11.313620259240494\n",
            "NSE    : 0.12262152203518051\n",
            "AKURASI: 88.6863797407595\n",
            "\n",
            " Results from Grid Search \n",
            "\n",
            " The best estimator across ALL searched params:\n",
            " GradientBoostingRegressor(learning_rate=0.3, n_estimators=7, subsample=0.7)\n",
            "\n",
            " The best parameters across ALL searched params:\n",
            " {'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 7, 'subsample': 0.7}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f98aa22eb50>]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#2. Gradient Boosting\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn import metrics\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters={\n",
        "    'learning_rate': [0.01, 0.1, 0.3, 0.5, 0.7, 1.0], #0.0 - inf\n",
        "    'n_estimators': [1, 3, 5, 7, 10, 15, 20, 100], #1 - inf\n",
        "    'subsample':[0.1, 0.3, 0.5, 0.7, 1], #0-1\n",
        "    'max_depth': [1, 3, 5, 7, 10, 15], #1-inf\n",
        "    }\n",
        "gb = GradientBoostingRegressor()\n",
        "regr_gb = GridSearchCV(gb, parameters)\n",
        "regr_gb.fit(X_train, y_train)\n",
        "\n",
        "y_pred = regr_gb.predict(X_test)\n",
        "\n",
        "r2=regr_gb.best_score_\n",
        "rmse=np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
        "mape=np.mean(np.abs((y_test - y_pred)/y_test))*100\n",
        "nse=1-(np.sum((y_test-y_pred)**2)/np.sum((y_test-np.mean(y_pred))**2))\n",
        "akurasi=100-np.mean(np.abs((y_test - y_pred)/y_test))*100\n",
        "best_estimator=regr_gb.best_estimator_\n",
        "best_param= regr_gb.best_params_\n",
        "\n",
        "print(\"Gradient Boosting\")\n",
        "print('R2     :', r2)\n",
        "print('RMSE   :', rmse)\n",
        "print('MAPE   :', mape)\n",
        "print('NSE    :', nse)\n",
        "print('AKURASI:', akurasi)\n",
        "print(\"\\n Results from Grid Search \" )\n",
        "print(\"\\n The best estimator across ALL searched params:\\n\", best_estimator)\n",
        "print(\"\\n The best parameters across ALL searched params:\\n\", best_param)\n",
        "\n",
        "#Simpan semua hasil statistik dalam file csv\n",
        "import csv  \n",
        "header1 = ['R2', 'RMSE', 'MAPE', 'NSE', 'AKURASI', 'Best Estimator', 'Best Parameter']\n",
        "data1 = [r2, rmse, mape, nse, akurasi, best_estimator, best_param]\n",
        "header2 = ['y_test']\n",
        "data2 = [y_test]\n",
        "header3 = ['y_pred']\n",
        "data3 = [y_pred]\n",
        "\n",
        "model='gb'\n",
        "nama_file='data_statistik' + '_' + model + '_' + pc + '_' + unsur + '.csv'\n",
        "\n",
        "with open(nama_file, 'w', encoding='UTF8') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(header1)\n",
        "    writer.writerow(data1)\n",
        "    writer.writerow(\"\\n\")\n",
        "    writer.writerow(header2)\n",
        "    writer.writerow(data2)\n",
        "    writer.writerow(\"\\n\")\n",
        "    writer.writerow(header3)\n",
        "    writer.writerow(data3)\n",
        "\n",
        "# Plot grafik regresi\n",
        "plt.scatter(y_test,y_pred)\n",
        "plt.plot(y_test,y_test,'r')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMgP6xMSsbVD"
      },
      "outputs": [],
      "source": [
        "#3 Support Vector Machine\n",
        "from sklearn.svm import SVR\n",
        "from sklearn import metrics\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters={\n",
        "    'C': [1.0, 2.0, 5.0, 7.0, 10.0], #positif\n",
        "    'epsilon': [0.1, 0.3, 0.5, 0.7, 1.0],\n",
        "    'gamma':['scale', 'auto'],\n",
        "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "    }\n",
        "svr = SVR()\n",
        "regr_svr = GridSearchCV(svr, parameters)\n",
        "regr_svr.fit(X_train, y_train)\n",
        "\n",
        "y_pred = regr_svr.predict(X_test)\n",
        "\n",
        "r2=regr_svr.best_score_\n",
        "rmse=np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
        "mape=np.mean(np.abs((y_test - y_pred)/y_test))*100\n",
        "nse=1-(np.sum((y_test-y_pred)**2)/np.sum((y_test-np.mean(y_pred))**2))\n",
        "akurasi=100-np.mean(np.abs((y_test - y_pred)/y_test))*100\n",
        "best_estimator=regr_svr.best_estimator_\n",
        "best_param= regr_svr.best_params_\n",
        "\n",
        "print(\"Support Vector Machine\")\n",
        "print('R2     :', r2)\n",
        "print('RMSE   :', rmse)\n",
        "print('MAPE   :', mape)\n",
        "print('NSE    :', nse)\n",
        "print('AKURASI:', akurasi)\n",
        "print(\"\\n Results from Grid Search \" )\n",
        "print(\"\\n The best estimator across ALL searched params:\\n\", best_estimator)\n",
        "print(\"\\n The best parameters across ALL searched params:\\n\", best_param)\n",
        "\n",
        "#Simpan semua hasil statistik dalam file csv\n",
        "import csv  \n",
        "header1 = ['R2', 'RMSE', 'MAPE', 'NSE', 'AKURASI', 'Best Estimator', 'Best Parameter']\n",
        "data1 = [r2, rmse, mape, nse, akurasi, best_estimator, best_param]\n",
        "header2 = ['y_test']\n",
        "data2 = [y_test]\n",
        "header3 = ['y_pred']\n",
        "data3 = [y_pred]\n",
        "\n",
        "model='svm'\n",
        "nama_file='data_statistik' + '_' + model + '_' + pc + '_' + unsur + '.csv'\n",
        "\n",
        "with open(nama_file, 'w', encoding='UTF8') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(header1)\n",
        "    writer.writerow(data1)\n",
        "    writer.writerow(\"\\n\")\n",
        "    writer.writerow(header2)\n",
        "    writer.writerow(data2)\n",
        "    writer.writerow(\"\\n\")\n",
        "    writer.writerow(header3)\n",
        "    writer.writerow(data3)\n",
        "\n",
        "# Plot grafik regresi\n",
        "plt.scatter(y_test,y_pred)\n",
        "plt.plot(y_test,y_test,'r')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CWhhm_n6A81l",
        "outputId": "ebe969ec-c357-427d-eec0-020c6353eaf2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 37\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 39\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 36\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 38\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 39\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 37\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 39\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 36\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 38\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 39\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 37\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 39\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 36\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 38\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 39\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 37\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 39\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 36\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 38\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 39\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 37\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 39\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 36\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 38\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 39\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 37\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 39\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 36\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 38\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 39\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 37\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 39\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 36\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 38\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 39\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 37\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 39\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 36\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 38\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 39\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 37\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 39\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 36\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 38\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 39\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 37\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 39\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 36\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 38\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 39\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 37\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 39\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 36\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 38\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 39\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 37\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 39\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 36\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 38\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 39\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 37\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 39\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 36\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 38\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 39\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 37\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 39\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 36\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 38\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Partial Least Square\n",
            "R2     : -0.010940438848720601\n",
            "RMSE   : 5.893168856443132\n",
            "MAPE   : 11.624686443571187\n",
            "NSE    : 0.19418055076128837\n",
            "AKURASI: 88.37531355642881\n",
            "\n",
            " Results from Grid Search \n",
            "\n",
            " The best estimator across ALL searched params:\n",
            " PLSRegression(max_iter=300, n_components=3)\n",
            "\n",
            " The best parameters across ALL searched params:\n",
            " {'max_iter': 300, 'n_components': 3}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 39\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 37\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 39\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 36\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 38\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cross_decomposition/_pls.py:305: UserWarning: Y residual is constant at iteration 39\n",
            "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f98a49a0f90>]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#4. PLS\n",
        "from sklearn.cross_decomposition import PLSRegression\n",
        "from sklearn import metrics\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters={\n",
        "    'n_components': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 40, 60, 80, 100, 120],\n",
        "    'max_iter' : [300, 500, 1000]\n",
        "    }\n",
        "pls = PLSRegression()\n",
        "regr_pls = GridSearchCV(pls, parameters)\n",
        "regr_pls.fit(X_train, y_train)\n",
        "\n",
        "y_pred = regr_pls.predict(X_test)\n",
        "\n",
        "r2=regr_pls.best_score_\n",
        "rmse=np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
        "mape=np.mean(np.abs((y_test.ravel() - y_pred.ravel())/y_test.ravel()))*100\n",
        "nse=1-(np.sum((y_test.ravel()-y_pred.ravel())**2)/np.sum((y_test.ravel()-np.mean(y_pred.ravel()))**2))\n",
        "akurasi=100-np.mean(np.abs((y_test.ravel() - y_pred.ravel())/y_test.ravel()))*100\n",
        "best_estimator=regr_pls.best_estimator_\n",
        "best_param= regr_pls.best_params_\n",
        "\n",
        "print(\"Partial Least Square\")\n",
        "print('R2     :', r2)\n",
        "print('RMSE   :', rmse)\n",
        "print('MAPE   :', mape)\n",
        "print('NSE    :', nse)\n",
        "print('AKURASI:', akurasi)\n",
        "print(\"\\n Results from Grid Search \")\n",
        "print(\"\\n The best estimator across ALL searched params:\\n\", best_estimator)\n",
        "print(\"\\n The best parameters across ALL searched params:\\n\", best_param)\n",
        "\n",
        "#Simpan semua hasil statistik dalam file csv\n",
        "import csv  \n",
        "header1 = ['R2', 'RMSE', 'MAPE', 'NSE', 'AKURASI', 'Best Estimator', 'Best Parameter']\n",
        "data1 = [r2, rmse, mape, nse, akurasi, best_estimator, best_param]\n",
        "header2 = ['y_test']\n",
        "data2 = [y_test]\n",
        "header3 = ['y_pred']\n",
        "data3 = [y_pred]\n",
        "\n",
        "model='pls'\n",
        "nama_file='data_statistik' + '_' + model + '_' + pc + '_' + unsur + '.csv'\n",
        "\n",
        "with open(nama_file, 'w', encoding='UTF8') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(header1)\n",
        "    writer.writerow(data1)\n",
        "    writer.writerow(\"\\n\")\n",
        "    writer.writerow(header2)\n",
        "    writer.writerow(data2)\n",
        "    writer.writerow(\"\\n\")\n",
        "    writer.writerow(header3)\n",
        "    writer.writerow(data3)\n",
        "\n",
        "# Plot grafik regresi\n",
        "plt.scatter(y_test,y_pred)\n",
        "plt.plot(y_test,y_test,'r')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8RJ8s3zClHR"
      },
      "outputs": [],
      "source": [
        "#5. Deep Neural Network\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "# deeper or wider\n",
        "regr_dnn = Sequential()\n",
        "regr_dnn.add(Dense(1024, input_dim=136, kernel_initializer='normal', activation='relu'))\n",
        "regr_dnn.add(Dense(1024, kernel_initializer='normal', activation='relu'))\n",
        "regr_dnn.add(Dense(512, kernel_initializer='normal', activation='relu'))\n",
        "regr_dnn.add(Dense(512, kernel_initializer='normal', activation='relu'))\n",
        "regr_dnn.add(Dense(512, kernel_initializer='normal', activation='relu'))\n",
        "regr_dnn.add(Dense(256, kernel_initializer='normal', activation='relu'))\n",
        "regr_dnn.add(Dense(256, kernel_initializer='normal', activation='relu'))\n",
        "regr_dnn.add(Dense(256, kernel_initializer='normal', activation='relu'))\n",
        "regr_dnn.add(Dense(128, kernel_initializer='normal', activation='relu'))\n",
        "regr_dnn.add(Dense(128, kernel_initializer='normal', activation='relu'))\n",
        "regr_dnn.add(Dense(128, kernel_initializer='normal', activation='relu'))\n",
        "regr_dnn.add(Dense(64, kernel_initializer='normal', activation='relu'))\n",
        "regr_dnn.add(Dense(64, kernel_initializer='normal', activation='relu'))\n",
        "regr_dnn.add(Dense(64, kernel_initializer='normal', activation='relu'))\n",
        "regr_dnn.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
        "regr_dnn.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
        "regr_dnn.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
        "regr_dnn.add(Dense(16, kernel_initializer='normal', activation='relu'))\n",
        "regr_dnn.add(Dense(16, kernel_initializer='normal', activation='relu'))\n",
        "regr_dnn.add(Dense(16, kernel_initializer='normal', activation='relu'))\n",
        "regr_dnn.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
        "regr_dnn.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
        "regr_dnn.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
        "regr_dnn.add(Dense(4, kernel_initializer='normal', activation='relu'))\n",
        "regr_dnn.add(Dense(4, kernel_initializer='normal', activation='relu'))\n",
        "regr_dnn.add(Dense(4, kernel_initializer='normal', activation='relu'))\n",
        "regr_dnn.add(Dense(1, kernel_initializer='normal'))\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.00001)\n",
        "regr_dnn.compile(optimizer=optimizer,loss='mse')\n",
        "\n",
        "regr_dnn.fit(x=X_train,y=y_train,\n",
        "          validation_data=(X_test,y_test),\n",
        "          batch_size=8,epochs=1500)\n",
        "\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error,explained_variance_score, mean_absolute_percentage_error\n",
        "y_pred = regr_dnn.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "r2=r2_score(y_test, y_pred)\n",
        "rmse=np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
        "mape=np.mean(np.abs((y_test.ravel() - y_pred.ravel())/y_test.ravel()))*100\n",
        "nse=1-(np.sum((y_test.ravel()-y_pred.ravel())**2)/np.sum((y_test.ravel()-np.mean(y_pred.ravel()))**2))\n",
        "akurasi=100-np.mean(np.abs((y_test.ravel() - y_pred.ravel())/y_test.ravel()))*100\n",
        "\n",
        "print(\"Deep Neural Network\")\n",
        "print('R2     :', r2)\n",
        "print('RMSE   :', rmse)\n",
        "print('MAPE   :', mape)\n",
        "print('NSE    :', nse)\n",
        "print('AKURASI:', akurasi)\n",
        "\n",
        "#Simpan semua hasil statistik dalam file csv\n",
        "import csv  \n",
        "header1 = ['R2', 'RMSE', 'MAPE', 'NSE', 'AKURASI']\n",
        "data1 = [r2, rmse, mape, nse, akurasi]\n",
        "header2 = ['y_test']\n",
        "data2 = [y_test]\n",
        "header3 = ['y_pred']\n",
        "data3 = [y_pred]\n",
        "\n",
        "model='dnn'\n",
        "nama_file='data_statistik' + '_' + model + '_' + pc + '_' + unsur + '.csv'\n",
        "\n",
        "with open(nama_file, 'w', encoding='UTF8') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(header1)\n",
        "    writer.writerow(data1)\n",
        "    writer.writerow(\"\\n\")\n",
        "    writer.writerow(header2)\n",
        "    writer.writerow(data2)\n",
        "    writer.writerow(\"\\n\")\n",
        "    writer.writerow(header3)\n",
        "    writer.writerow(data3)\n",
        "\n",
        "# Plot grafik regresi\n",
        "plt.scatter(y_test,y_pred)\n",
        "plt.plot(y_test,y_test,'r')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}